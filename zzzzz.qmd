---
title: "아디다스, 나이키 기사 비교분석"
format: html
author: 언론홍보학과 2019102107 김지후
title-block-style: default
title-block-banner: "#6E6E6E"
date: 2022-10-12
code-fold: true
code-tools: true
---

# 목차

## ★ 들어가면서... 

### 1. 주제선정이유
### 2. 데이터셋 출처


## ★ 필요 패키지 설치 

## ★ 자료분석 

### 1. 총빈도 분석
### 2. 감정사전분석
### 3. 가중치분석
### 4. 토픽 모델링 
### 5. 정리 






# 주제선정이유 
### 나이키와 아디다스가 대립 브랜드이기에 이번 기회에 비교분석을 해서 
### 각 브랜드가 어떤 이미지로 비춰지고 있고 어떤 방향성이 필요한지 알아보고 싶어
## 이주제를 선정하게 되었습니다





# 데이터셋의 출처
### 데이터셋의 출처는 빅카인즈이고,
### 기사의 기간은 2021년 10월부터 추출했습니다. 







## 필요패키지 설치 

```{r}
#| warning: false

install.packages("readxl",repos = "http://cran.us.r-project.org")
install.packages("tidyverse",repos = "http://cran.us.r-project.org")
install.packages("tidytext",repos = "http://cran.us.r-project.org")
install.packages("kableExtra",repos = "http://cran.us.r-project.org")
install.packages("wordcloud",repos = "http://cran.us.r-project.org")
install.packages("tidylo",repos = "http://cran.us.r-project.org")
install.packages("RcppMeCab",repos = "http://cran.us.r-project.org")

library(tidylo)
library(tidyverse)
library(tidytext)
library(kableExtra)
library(wordcloud)
library(readxl)
```

```{r}
list.files("data/.")

list.files("data/knusenti/KnuSentiLex-master/")

senti_name_v <- list.files("data/knusenti/KnuSentiLex-master/.")[9]

senti_name_v

read_lines(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v)) %>% head(10)

read_lines(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v)) %>% 
  head(10) %>% str_extract("\t|\n| ")

read_tsv(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v)) %>% head(10)
read_tsv(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v), col_names = F) %>% head(10)

senti_dic_df <- read_tsv(str_c("data/knusenti/KnuSentiLex-master/", senti_name_v), col_names = F)

glimpse(senti_dic_df)

senti_dic_df[1-5, ]

senti_dic_df <- senti_dic_df %>% rename(word = X1, sScore = X2)
glimpse(senti_dic_df)

pkg_v <- c("tidyverse", "tidytext","RcppMeCab")

lapply(pkg_v, require, ch = T)

install.packages("stm", dependencies = T,repos = "http://cran.us.r-project.org")

install.packages("gt",repos = "http://cran.us.r-project.org")
```


```{r}

m_df <- readxl::read_excel("나이키.xlsx") %>% 
  select(제목, 본문)

s_df <- readxl::read_excel("아디다스.xlsx") %>% 
  select(제목, 본문)


```



# 단어 총빈도 분석 
```{r}

m_df2 <- m_df %>% 
  distinct(제목, .keep_all = T) %>% 
  mutate(ID = factor(row_number())) %>% 
  mutate(label = "0") %>%
  unite(제목, 본문, col = "text", sep = " ") %>% 
  mutate(text = str_squish(text))

m_tk <- m_df2 %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = "regex", drop = F) %>%
  count(word, sort = T)

m_tk <- 
m_tk %>% 
  filter(!word %in% c("나이키","있다","밝혔다","기자","통해")) %>% 
  filter(str_detect(word, "[:alpha:]+")) %>%
  filter(str_length(word) > 1) %>%
  slice_max(n, n = 15) %>% 
  mutate(word = reorder(word, n))

m_tk %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
  labs(title = "나이키 단어 총빈도 분석")
```
### ★러시아가 상위 주제어에 있었으나, 그 수가 너무 많아 후에 분석에 방해되어 삭제했습니다. 
### ★매년 블랙프라이데이에 패션플랫폼에서 할인이벤트 등을 해 상위어에 나왔습니다
### ★기술발전과, 코로나 이후에 나이키가 메타버스시장개발에 집중하게되었고,
### ★중국에 메타버스 관련 유명 개발자가 있어 중국이 상위어로 같이 나왔습니다. 
### ★아디다스에는 나이키가 상위어인데 반해 나이키는 아디다스가 상위어로 나오지 않았습니다.


```{r}

s_df2 <- s_df %>% 
  distinct(제목, .keep_all = T) %>% 
  mutate(ID = factor(row_number())) %>% 
  mutate(label = "0") %>%
  unite(제목, 본문, col = "text", sep = " ") %>% 
  mutate(text = str_squish(text))

s_tk <- s_df2 %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = "regex", drop = F) %>%
  count(word, sort = T)

s_tk <- 
s_tk %>% 
  filter(!word %in% c("아디다스","있다","따르면","밝혔다","지난","기자","최근","있는","미국","일까지","일부터","머니투데이","통해","대한","것으로","오는","이번","아시아경제","7일")) %>% 
  filter(str_detect(word, "[:alpha:]+")) %>%
  filter(str_length(word) > 1) %>%
  slice_max(n, n = 15) %>% 
  mutate(word = reorder(word, n))

s_tk %>%
  ggplot(aes(word, n)) +
  geom_col() +
  coord_flip() +
  labs(title = "아디다스 단어 총빈도 분석")
```

## 카타르 월드컵의 공인구나 협업 브랜드가 아디다스로 선정됨
### ★손흥민이 아디다스의 모델로 선정되어 상위어에 위치함 
### ★포토가 상위어에 있었으나, 포토존이나 여러 연예인들의 사진을 포토로 지정해 관련이 없다고 판단하여, 삭제함 
### ★가장 대적되는 기업인 나이키또한 아디다스 총빈도 분석에서 상위어에 들정도로 기사가 많이 남 



### 정리하면, 나이키에서 메타버스와 nft는 새로운 시장 개척지로 선정되어 
### 그와 관련된 중국의 유명 개발자가 있어 상위어에 중국이 나오게 되었고, 
### 아디다스는 카타르 월드컵 대표 브랜드로 선정되어 카타르 월드컵 관련 주제어가 많이나오는 반면
### 나이키는 상위어빈도가 크게 차이 나지않게 고루고루 분포되어 있고
### 그리고 같은 기간내에 나이키의 기사수가 아디다스보다 약 500개정도 더 많았습니다.






# 긍, 부정어 분석 

```{r}

m_s_df <- m_df2 %>% 
  unnest_tokens(word, text, token = "regex") %>% 
  inner_join(senti_dic_df) %>% 
  count(word, sScore, sort = T) %>% 
  filter(!word %in% c("할인","세일","이벤트","함께")) %>%
  filter(str_length(word) > 1) %>% 
  mutate(word = reorder(word, n)) %>% 
  slice_head(n = 20)

m_s_df %>% 
  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +
    labs(title = "나이키감성분석")

```



```{r}

s_s_df <- s_df2 %>% 
  unnest_tokens(word, text, token = "regex") %>% 
  inner_join(senti_dic_df) %>% 
  count(word, sScore, sort = T) %>% 
  filter(!word %in% c("할인","세일","함께")) %>%
  filter(str_length(word) > 1) %>% 
  mutate(word = reorder(word, n)) %>% 
  slice_head(n = 20)


s_s_df %>% 
  ggplot() + geom_col(aes(n, word, fill = sScore), show.legend = F) +
    labs(title = "아디다스 감성분석")


```

## 두 브랜드 모두 긍정 단어 중 함께,할인,세일이 너무 많고, 딱히 긍정적 의미로 쓰이지 않는 것 같아 삭제했습니다. 


```{r}

m_df2 %>% 
  unnest_tokens(word, text) %>% 
  left_join(senti_dic_df) %>% 
  mutate(sScore = ifelse(sScore >= 1, "긍정",
                         ifelse(sScore <= -1, "부정", "중립"))) 

m_df2 %>%   
  unnest_tokens(word, text, token = "regex") %>% 
  inner_join(senti_dic_df) %>% 
  mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%
  mutate(label = ifelse(sScore > 0, "1", ifelse(sScore < 0, "0", "2"))) %>%
  filter(label != "중립") %>%
  filter(!word %in% c("할인","세일","이벤트","없다","함께")) %>%
  count(word, emotion, label, sort = T) %>%
  filter(str_length(word) > 1) %>%
  group_by(label = ifelse(label > 0, "긍정", "부정")) %>%
  slice_head(n = 15) %>%
  ggplot(aes(x = n,
             y = reorder(word, n), fill = label)) +
  geom_col(show.legend = F) +
  facet_wrap(~label, scale = "free") +
  labs(title = "나이키 긍,부정어")
```
### ★ 나이키의 긍정어로 최고, 인기, 함께 등이 나왔고 
### ★ 부정어로는 살인, 눈물, 위기등이 나온 이유는 나이키 ceo의 과거 살인 행적 고백때문에 나온 것입니다. 
### ★ 긍정어의 수가 대체로 많은 것을 보아 긍정적인 이미지로 보여지는 것을 알 수 있습니다. 
```{r}

s_df2 %>% 
  unnest_tokens(word, text) %>% 
  filter(!word %in% c("피해")) %>%
  left_join(senti_dic_df) %>% 
  mutate(sScore = ifelse(sScore >= 1, "긍정",
                         ifelse(sScore <= -1, "부정", "중립"))) 

s_df2 %>%   
  unnest_tokens(word, text, token = "regex") %>% 
  inner_join(senti_dic_df) %>% 
  mutate(emotion = ifelse(sScore > 0, "긍정", ifelse(sScore < 0, "부정", "중립"))) %>%
  mutate(label = ifelse(sScore > 0, "1", ifelse(sScore < 0, "0", "2"))) %>%
  filter(label != "중립") %>%
  filter(!word %in% c("할인","세일","이벤트","함께")) %>%
  count(word, emotion, label, sort = T) %>%
  filter(str_length(word) > 1) %>%
  group_by(label = ifelse(label > 0, "긍정", "부정")) %>%
  slice_head(n = 15) %>%
  ggplot(aes(x = n,
             y = reorder(word, n), fill = label)) +
  geom_col(show.legend = F) +
  facet_wrap(~label, scale = "free") +
  labs(title = "아디다스 긍,부정어")
```
### ★ 아디다스의 긍정어로 최고, 세계적인, 젊은등이 나이키와 같이 나왔고 
### ★ 부정어로 비난, 다툼을 등이 나온 이유는 아디다스 모델인 칸예 웨스트의 혐오발언으로 계약을  해지해서 입니다. 
### ★ 나이키와의 기사수의 차이가 있지만, 아디다스의 긍정, 부정어의 비율에서 긍정적인 기사수가 좀 더 높은 것으로 파악됩니다. 


### 정리하면, 나이키는 ceo의 살인을 고백한 것으로 부정적인 기사가 많이 나왔고, 그에 반해 아디다스는 카타르월드컵에 공식협업 브랜드로 선정되는 등의 차이로 긍정,부정어의 비율에서 차이가 난다고 볼 수 있었습니다. 



```{r}

weighted_log_odds_df1 <-
  bind_rows(m_tk, s_tk, .id = "party") %>% 
  bind_log_odds(set = party,
                feature = word, 
                n = n) %>% 
  arrange(-log_odds_weighted)
```

# 상대빈도분석 
```{r}

library(gt)
library(dplyr)

m.s_df <- bind_cols(
  weighted_log_odds_df1 %>%   
  group_by(party = ifelse(party == 1, "나이키", "아디다스")) %>% 
  arrange(party) %>% 
  select(-party) %>%
  head(15),
  
  weighted_log_odds_df1 %>%   
  group_by(party = ifelse(party == 1, "나이키", "아디다스")) %>% 
  arrange(desc(party)) %>% 
  select(-party) %>%
  head(15) 
  ) 

m.s_df <- m.s_df[-c(1,5)]


m.s_df %>%
  gt() %>% tab_header(
  "상대 빈도 분석"
  ) %>% tab_spanner(
    label = "나이키 기준",
    columns = 1:3
  ) %>% tab_spanner(
    label = "아디다스 기준",
    columns = 4:6
  ) %>% cols_label(
    word...2 = "명사",
    n...3 = "빈도",
    log_odds_weighted...4 = "가중상대빈도",
    word...6 = "명사",
    n...7 = "빈도",
    log_odds_weighted...8 = "가중상대빈도"
  ) %>% fmt_number(
    columns = starts_with("log"), 
    decimals = 2
  )
```

## 나이키에서는 메타버스 쪽 단어들이 많이 보이고, 
## 아디다스는 카타르월드컵의 단어들이 많이 보입니다. 
### 하지만 아디다스 관련 기사 상위어에만 나이키가 있는 것을 볼 수 있습니다. 


```{r}

s_ttk <- s_df2 %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = "regex", drop = F)

s_ttk <- 
s_ttk %>%
  filter(str_detect(word, "[:alpha:]+"))%>%
  filter(!word %in% c("아디다스","있다","일까지","참석해","열린","오는"))

s_cdf <- s_ttk %>%
  group_by(ID) %>%
  summarise(text2 = str_flatten(word, " ")) %>%
  ungroup() %>% 
  inner_join(s_df2, by = "ID")

library(stm)
library(tm)

processed <- s_df2 %>% 
  textProcessor(
    documents = s_cdf$text2,
    metadata = .,
    wordLengths = c(2, Inf))

```

```{r}

out <- 
  prepDocuments(processed$documents,
                     processed$vocab,
                     processed$meta,
                 lower.thresh = 0)

```

```{r}

docs <- out$documents
vocab <- out$vocab
meta <- out$meta

```

```{r}

topicN <- c(3, 10)



```


```{r}

s_stm_fit <-
 stm(
    documents = docs,
    vocab = vocab,
    K = 6,
    data = meta,
    max.em.its = 75,
    init.type = "Spectral",
    seed = 25,
    verbose = F
  )

```

# 토픽모델링 

```{r}

   
s_topic_name <- tibble(topic = 1:6,
                     name = c("1. 카타르 월드컵",
                              "2. 코로나 이후",
                              "3. 할인 행사",
                              "4. 아이돌 계약",
                              "5.",
                              "6. 메타버스시장"))

s_td_beta <- s_stm_fit %>% tidy(matrix = 'beta')

s_topic_name <- s_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 7) %>% 
  left_join(s_topic_name, by = "topic")

s_topic_name %>% 
  ggplot(aes(x = beta, 
             y = reorder_within(term, beta, name),  
             fill = name)) +
  geom_col(show.legend = F) +
  facet_wrap(~name, scales = "free") +
  scale_y_reordered() +                             
  labs(x = expression("단어 확률분포: "~beta), y = NULL,
       title = "수자원 주제별 단어 확률 분포") +
  theme(plot.title = element_text(size = 20))


```

## 토픽모델링

### 아디다스는 카타르 월드컵과, 아이돌과의 계약등이 눈에 띄는 토픽이었습니다. 
### 아디다스도 메타버스 시장에 뛰어들고 있지만, 그 수가 나이키에 비해 부족합니다. 
### 아디다스는 구찌 같은 브랜드나, 아이돌과 협업하는 등의 노력을 볼 수 있었습니다. 
```{r} 

s_td_gamma <- s_stm_fit %>% tidy(matrix = "gamma") 
s_top_terms <- 
s_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 5) %>% 
  select(topic, term) %>% 
  summarise(terms = str_flatten(term, collapse = ", ")) 

s_gamma_terms <- 
s_td_gamma %>% 
  group_by(topic) %>% 
  summarise(gamma = mean(gamma)) %>% 
  left_join(s_top_terms, by = 'topic') %>% 
  left_join(s_topic_name, by = 'topic')
  
s_gamma_terms %>% 
  
  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +
  geom_col(show.legend = F) +
  geom_text(aes(label = round(gamma, 2)), 
            hjust = 1.15) +                
  geom_text(aes(label = terms), 
            hjust = -0.05) +              
  labs(x = expression("문서 확률분포"~(gamma)), y = NULL,
       title = "아디다스 토픽 상위 주제어") +
  theme(plot.title = element_text(size = 20))

```

```{r}

m_ttk <- m_df2 %>% 
  mutate(text = str_remove_all(text, "[^(\\w+|\\s)]")) %>%  
  unnest_tokens(word, text, token = "regex", drop = F)

m_ttk <- 
m_ttk %>%
  filter(str_detect(word, "[:alpha:]+"))%>%
  filter(!word %in% c("나이키", "일까지","일부터","있다","밝혔다","대한","최근","지난")) 

m_cdf <- m_ttk %>%
  group_by(ID) %>%
  summarise(text2 = str_flatten(word, " ")) %>%
  ungroup() %>% 
  inner_join(m_df2, by = "ID")

library(stm)
library(tm)

processed <- m_df2 %>% 
  textProcessor(
    documents = m_cdf$text2,
    metadata = .,
    wordLengths = c(2, Inf))

```

```{r}

out <- 
  prepDocuments(processed$documents,
                     processed$vocab,
                     processed$meta,
                 lower.thresh = 0)

```

```{r}

docs <- out$documents
vocab <- out$vocab
meta <- out$meta

```

```{r}

topicN <- c(3, 10)



```


```{r}

m_stm_fit <-
 stm(
    documents = docs,
    vocab = vocab,
    K = 6,
    data = meta,
    max.em.its = 75,
    init.type = "Spectral",
    seed = 25,
    verbose = F
  )

```


```{r}

   
m_topic_name <- tibble(topic = 1:6,
                     name = c("1. 주식시장",
                              "2. 메타버스시장",
                              "3. 패션플랫폼",
                              "4. 메타버스 시장2",
                              "5. 블랙프라이데이",
                              "6. 에어조던"))

m_td_beta <- m_stm_fit %>% tidy(matrix = 'beta')

m_topic_name <- m_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 7) %>% 
  left_join(m_topic_name, by = "topic")

m_topic_name %>% 
  ggplot(aes(x = beta, 
             y = reorder_within(term, beta, name),  
             fill = name)) +
  geom_col(show.legend = F) +
  facet_wrap(~name, scales = "free") +
  scale_y_reordered() +                             
  labs(x = expression("단어 확률분포: "~beta), y = NULL,
       title ="나이키 주제별 단어 확률 분포") +
  theme(plot.title = element_text(size = 20))


```
## 주식시장이 토픽모델링이 된 이유는 미국증시가 논란이 되면서 갑작스럽게 주식관련 기사가 많아졌지 때문이고,
## 메타버스 관련 토픽모델링에 우크라이나가 있는 이유는 원인은 파악하지 못했으나. 
## 러.우전쟁으로 러시아에 있는 나이키 매장을 철수했기 때문입니다. 

```{r} 

m_td_gamma <- m_stm_fit %>% tidy(matrix = "gamma") 
m_top_terms <- 
m_td_beta %>% 
  group_by(topic) %>% 
  slice_max(beta, n = 5) %>% 
  select(topic, term) %>% 
  summarise(terms = str_flatten(term, collapse = ", ")) 

m_gamma_terms <- 
m_td_gamma %>% 
  group_by(topic) %>% 
  summarise(gamma = mean(gamma)) %>% 
  left_join(m_top_terms, by = 'topic') %>% 
  left_join(m_topic_name, by = 'topic')
  
m_gamma_terms %>% 
  ggplot(aes(x = gamma, y = reorder(name, gamma), fill = name)) +
  geom_col(show.legend = F) +
  geom_text(aes(label = round(gamma, 2)), 
            hjust = 1.15) +                
  geom_text(aes(label = terms), 
            hjust = -0.05) +              
  labs(x = expression("문서 확률분포"~(gamma)), y = NULL,
       title = "나이키 토픽 상위 주제어") +
  theme(plot.title = element_text(size = 20))

```



## 정리


### 나이키는 현재 22년 초에 ceo의 살인과거를 고백하고, 잠시 휘청했으나 다시 회복하는 모양을 보이고 있습니다.
### 코로나 이후 나이키는 메타버스 시장의 가능성을 보고 그 쪽 시장에 집중하는 경향을 보이고 있습니다. 
### 현재는 아디다스가 카타르 월드컵에 공식 브랜드로 론칭되었으나, 최근 다시 유니폼 쪽에서 나이키가 강세를 보이고 있습니다. 

### 아디다스 기사에는 나이키가 자주 나오는 반면, 나이키기사에서는 아디다스가 많이 나오지는 않았고, 
### 이를 통해 전체적인 브랜드 인지도나, 사람들의 선호도는 나이키가 더 높은 것으로 파악했습니다. 

### 두 브랜드 모두 블랙프라이데이 기간이 다가오면 플랫폼에서 할인 행사등을 하는 기사가 많아지는 추세를 보여줬습니다. 

### 토픽모델링을 보면 아디다스는 협업 관련 론칭 관련이 많은 등의 여러 인지도를 높이기 위한 시도를 하고 있는 것을 알 수 있었습니다. 
